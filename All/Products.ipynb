{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find All Products From Products Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data consolidation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the path to the directory containing the text files\n",
    "directory_path = 'products'\n",
    "\n",
    "# Output file where consolidated data will be saved\n",
    "output_file = 'FinalProductsList.txt'\n",
    "\n",
    "# Read each file in the directory\n",
    "def read_product_files(directory):\n",
    "    products_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = file.read()\n",
    "                corrected_data = '[' + data.replace('}\\n\\n{', '},\\n{') + ']'\n",
    "                try:\n",
    "                    product_info = json.loads(corrected_data)\n",
    "                    products_data.append(product_info)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON from {filename}: {e}\")\n",
    "    return products_data\n",
    "\n",
    "# Extract product description specifically looking more robustly\n",
    "def extract_description(description_text):\n",
    "    # Attempt to extract the portion after \"Product Description\"\n",
    "    desc_start = description_text.find(\"Product Description:\")\n",
    "    if desc_start != -1:\n",
    "        # Extract starting from the found index through the end of the description\n",
    "        desc_substr = description_text[desc_start:]\n",
    "        desc_end = desc_substr.find(\"<br/>\")\n",
    "        if desc_end != -1:\n",
    "            return desc_substr[len(\"Product Description:\"):desc_end].strip()\n",
    "        else:\n",
    "            return desc_substr[len(\"Product Description:\"):].strip()\n",
    "    return \"Description not found.\"\n",
    "\n",
    "# Write the consolidated product info to an output file\n",
    "def write_product_info(products_data, output_file):\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for i, product in enumerate(products_data, start=1):\n",
    "            product_dict = {}\n",
    "            for segment in product:\n",
    "                product_dict.update(segment)\n",
    "\n",
    "            product_name = product_dict.get(\"Product Name\", \"N/A\")\n",
    "            category_path = product_dict.get(\"Category\", \"N/A\").replace('\"', '')\n",
    "            brand_name = product_dict.get(\"Brand Name\", \"N/A\")\n",
    "            seller_name = product_dict.get(\"Seller Name\", \"N/A\")\n",
    "            url = product_dict.get(\"URL\", \"N/A\")\n",
    "            price_info = product_dict.get(\"Price Info\", [])\n",
    "            price_details = \" | \".join([f\"Original: {p[1]}, Discounted: {p[2]}\" for p in price_info])\n",
    "            # description = extract_description(product_dict.get(\"desc\", \"\").replace(\"<br/>\", \"\\n\"))\n",
    "            additional_info = product_dict.get(\"Additional Info\", {})\n",
    "            positive_ratings = additional_info.get(\"Positive Seller Ratings\", \"N/A\")\n",
    "            ship_on_time = additional_info.get(\"Ship on Time\", \"N/A\")\n",
    "            return_policy = product_dict.get(\"Return Policy\", {})\n",
    "            return_details = f\"{return_policy.get('Title', 'N/A')} ({return_policy.get('Subtitle', 'N/A')})\"\n",
    "\n",
    "            # product_entry = f\"Product {i:02d}: Product Name = {product_name}, Product Category = {category_path}, Brand Name = {brand_name}, Seller Name = {seller_name}, URL = {url}, Price Details = {price_details}, Description = {description}, Positive Seller Ratings = {positive_ratings}, Ship on Time = {ship_on_time}, Return Policy = {return_details}\\n\"\n",
    "            product_entry = f\"Product {i:02d}: Product Name = {product_name}, Product Category = {category_path}, Brand Name = {brand_name}, Seller Name = {seller_name}, URL = {url}, Price Details = {price_details}, Positive Seller Ratings = {positive_ratings}, Ship on Time = {ship_on_time}, Return Policy = {return_details}\\n\"\n",
    "            outfile.write(product_entry)\n",
    "\n",
    "# Main function to handle operations\n",
    "def main():\n",
    "    products_data = read_product_files(directory_path)\n",
    "    write_product_info(products_data, output_file)\n",
    "    print(\"Data consolidation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinalProductsList.txt To FinalProductsList.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# Path to the input text file\n",
    "input_file_path = 'FinalProductsList.txt'\n",
    "\n",
    "# Output CSV file\n",
    "output_csv_path = 'FinalProductsList.csv'\n",
    "\n",
    "# Column headers for the CSV file\n",
    "headers = [\n",
    "    \"Product Number\", \"Product Name\", \"Product Category\", \"Brand Name\", \"Seller Name\", \n",
    "    \"Price Details\", \"Positive Seller Ratings\", \"Ship on Time\", \"Return Policy\"\n",
    "]\n",
    "\n",
    "# Function to parse each line of the text file into structured data\n",
    "def parse_line(line):\n",
    "    # Prepare regex pattern with lookahead assertions to capture fields correctly\n",
    "    pattern = re.compile(\n",
    "        r\"Product Name = (?P<Product_Name>.*?)(?=, Product Category =)|\"\n",
    "        r\"Product Category = (?P<Product_Category>.*?)(?=, Brand Name =)|\"\n",
    "        r\"Brand Name = (?P<Brand_Name>.*?)(?=, Seller Name =)|\"\n",
    "        r\"Seller Name = (?P<Seller_Name>.*?)(?=, URL =)|\"\n",
    "        r\"Price Details = (?P<Price_Details>.*?)(?=, Positive Seller Ratings =)|\"\n",
    "        r\"Positive Seller Ratings = (?P<Positive_Seller_Ratings>.*?)(?=, Ship on Time =)|\"\n",
    "        r\"Ship on Time = (?P<Ship_on_Time>.*?)(?=, Return Policy =)|\"\n",
    "        r\"Return Policy = (?P<Return_Policy>.*?)(?=, Product \\d+:|, URL =|$)\"\n",
    "    )\n",
    "\n",
    "    # Extract product number separately\n",
    "    product_number = re.match(r\"Product (\\d+):\", line).group(1)\n",
    "\n",
    "    # Find all matches in the line\n",
    "    matches = pattern.finditer(line)\n",
    "    data = {k: v for m in matches for k, v in m.groupdict().items() if v is not None}\n",
    "\n",
    "    # Constructing the row based on required headers\n",
    "    return [\n",
    "        \"Product \" + product_number,\n",
    "        data.get(\"Product_Name\", \"\"),\n",
    "        data.get(\"Product_Category\", \"\"),\n",
    "        data.get(\"Brand_Name\", \"\"),\n",
    "        data.get(\"Seller_Name\", \"\"),\n",
    "        data.get(\"Price_Details\", \"\"),\n",
    "        data.get(\"Positive_Seller_Ratings\", \"\"),\n",
    "        data.get(\"Ship_on_Time\", \"\"),\n",
    "        data.get(\"Return_Policy\", \"\")\n",
    "    ]\n",
    "\n",
    "# Reading the text file and writing to CSV\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file, \\\n",
    "     open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)  # Writing headers to the CSV file\n",
    "    \n",
    "    for line in file:\n",
    "        if line.strip():  # Ensuring the line has content\n",
    "            row = parse_line(line)\n",
    "            writer.writerow(row)  # Writing the parsed data as a row in the CSV file\n",
    "\n",
    "print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Information From Queries Regarding Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'Show me watches under Rs. 500.' -> Subject: watches\n",
      "Query: 'Can you list watches between Rs. 1000 and Rs. 2000?' -> Subject: watches\n",
      "Query: 'Show me all Samsung watches available.' -> Subject: No clear subject found\n",
      "Query: 'Which watches do you have from Jianuo?' -> Subject: No clear subject found\n",
      "Query: 'List watches sold by New-Gen.' -> Subject: List watches\n",
      "Query: 'Show me the top-rated sellers who sell watches.' -> Subject: watches\n",
      "Query: 'Show me the top-rated sellers who sell shoes.' -> Subject: shoes\n",
      "Query: 'Show me watches from sellers with more than 90% positive ratings.' -> Subject: No clear subject found\n",
      "Query: 'Which watches are sold by highly rated sellers?' -> Subject: watches\n",
      "Query: 'Can you find watches that always ship on time?' -> Subject: watches\n",
      "Query: 'I'm looking for sports watches priced between Rs. 1500 and Rs. 2500, sold by top-rated sellers.' -> Subject: sports watches\n",
      "Query: 'What are the latest smartwatches available under Rs. 5000?' -> Subject: smartwatches\n",
      "Query: 'List all luxury watches.' -> Subject: luxury watches\n",
      "Query: 'Help me find a watch for a gift under Rs. 2000.' -> Subject: watch\n",
      "Query: 'List all the shoes available in blue colour.' -> Subject: shoes\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NLP model from spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Example queries, including your latest example about shoes\n",
    "queries = [\n",
    "    \"Show me watches under Rs. 500.\",\n",
    "    \"Can you list watches between Rs. 1000 and Rs. 2000?\",\n",
    "    \"Show me all Samsung watches available.\",\n",
    "    \"Which watches do you have from Jianuo?\",\n",
    "    \"List watches sold by New-Gen.\",\n",
    "    \"Show me the top-rated sellers who sell watches.\",\n",
    "    \"Show me the top-rated sellers who sell shoes.\",\n",
    "    \"Show me watches from sellers with more than 90% positive ratings.\",\n",
    "    \"Which watches are sold by highly rated sellers?\",\n",
    "    \"Can you find watches that always ship on time?\",\n",
    "    \"I'm looking for sports watches priced between Rs. 1500 and Rs. 2500, sold by top-rated sellers.\",\n",
    "    \"What are the latest smartwatches available under Rs. 5000?\",\n",
    "    \"List all luxury watches.\",\n",
    "    \"Help me find a watch for a gift under Rs. 2000.\",\n",
    "    \"List all the shoes available in blue colour.\"\n",
    "]\n",
    "\n",
    "# Keywords that are likely subjects in retail-related queries\n",
    "keywords = [\"watch\", \"watches\", \"shoes\", \"smartwatches\", \"luxury watches\", \"sports watches\"]\n",
    "\n",
    "# Function to clean and extract the subject from the query\n",
    "def extract_subject(query):\n",
    "    doc = nlp(query)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        cleaned_chunk = ' '.join([token.text for token in chunk if token.pos_ in ['NOUN', 'PROPN']])\n",
    "        if any(keyword in cleaned_chunk.lower() for keyword in keywords):\n",
    "            return cleaned_chunk\n",
    "    return \"No clear subject found\"\n",
    "\n",
    "# Process each query and print the subject\n",
    "for query in queries:\n",
    "    subject = extract_subject(query)\n",
    "    print(f\"Query: '{query}' -> Subject: {subject}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rs. 500'],\n",
       " ['between Rs. 1000 and Rs. 2000'],\n",
       " ['sold by samsung'],\n",
       " ['sold by new-gen'],\n",
       " ['top-rated sellers'],\n",
       " ['90%', 'more than 90% positive ratings'],\n",
       " ['top-rated sellers'],\n",
       " ['ship on time'],\n",
       " ['between Rs. 1500 and Rs. 2500', 'top-rated sellers'],\n",
       " ['Rs. 5000'],\n",
       " [],\n",
       " ['Rs. 2000']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# products_df = pd.read_csv('FinalProductsList.csv')\n",
    "\n",
    "# def extract_info_simple(query):\n",
    "#     # Define keywords for subject identification\n",
    "#     subject_keywords = [\"watch\", \"watches\", \"smartwatch\", \"luxury watch\"]\n",
    "#     brand_names = products_df['Brand Name'].str.lower().unique().tolist()\n",
    "#     seller_names = products_df['Seller Name'].str.lower().unique().tolist()\n",
    "\n",
    "#     # Patterns for limitations\n",
    "#     price_pattern = r\"Rs\\.\\s*\\d+|\\d+\\s*%|between\\s*Rs\\.\\s*\\d+\\s*and\\s*Rs\\.\\s*\\d+\"\n",
    "#     # Updated rating pattern to be more specific and catch contexts like \"more than 90%\"\n",
    "#     rating_pattern = r\"more than \\d{1,3}% positive ratings|less than \\d{1,3}% positive ratings|\\d{1,3}% positive ratings|\\d{1,3}%\"\n",
    "#     time_pattern = r\"ship on time\"\n",
    "    \n",
    "#     # Find subjects\n",
    "#     subjects = [keyword for keyword in subject_keywords if keyword in query.lower()]\n",
    "#     subjects.extend([brand for brand in brand_names if brand in query.lower()])\n",
    "    \n",
    "#     # Find limitations\n",
    "#     limitations = re.findall(price_pattern, query)\n",
    "#     limitations.extend(re.findall(rating_pattern, query))\n",
    "#     if \"top-rated sellers\" in query.lower() or \"highly rated sellers\" in query.lower():\n",
    "#         limitations.append(\"top-rated sellers\")\n",
    "#     if re.search(time_pattern, query, re.IGNORECASE):\n",
    "#         limitations.append(\"ship on time\")\n",
    "\n",
    "#     # Check if there are specific seller names mentioned\n",
    "#     for seller in seller_names:\n",
    "#         if seller in query.lower():\n",
    "#             limitations.append(f\"sold by {seller}\")\n",
    "\n",
    "#     # return {\"subjects\": subjects, \"limitations\": limitations}\n",
    "#     return limitations\n",
    "\n",
    "# # Redefining example queries\n",
    "# query_examples = [\n",
    "#     \"Show me watches under Rs. 500\",\n",
    "#     \"Can you list watches between Rs. 1000 and Rs. 2000?\",\n",
    "#     \"Show me all Samsung watches available.\",\n",
    "#     \"List watches sold by New-Gen.\",\n",
    "#     \"Show me the top-rated sellers who sell watches.\",\n",
    "#     \"Show me watches from sellers with more than 90% positive ratings.\",\n",
    "#     \"Which watches are sold by highly rated sellers?\",\n",
    "#     \"Can you find watches that always ship on time?\",\n",
    "#     \"I'm looking for sports watches priced between Rs. 1500 and Rs. 2500, sold by top-rated sellers.\",\n",
    "#     \"What are the latest smartwatches available under Rs. 5000?\",\n",
    "#     \"List all luxury watches.\",\n",
    "#     \"Help me find a watch for a gift under Rs. 2000.\"\n",
    "# ]\n",
    "\n",
    "# # Apply function to each example query\n",
    "# extracted_info = [extract_info_simple(query) for query in query_examples]\n",
    "# extracted_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "products_df = pd.read_csv('FinalProductsList.csv')\n",
    "\n",
    "def extract_info_simple(query):\n",
    "    # Define keywords for subject identification\n",
    "    subject_keywords = [\"watch\", \"watches\", \"smartwatch\", \"luxury watch\"]\n",
    "    brand_names = products_df['Brand Name'].str.lower().unique().tolist()\n",
    "    seller_names = products_df['Seller Name'].str.lower().unique().tolist()\n",
    "\n",
    "    # Patterns for limitations\n",
    "    price_pattern = r\"Rs\\.\\s*\\d+|\\d+\\s*%|between\\s*Rs\\.\\s*\\d+\\s*and\\s*Rs\\.\\s*\\d+\"\n",
    "    # Updated rating pattern to be more specific and catch contexts like \"more than 90%\"\n",
    "    rating_pattern = r\"more than \\d{1,3}% positive ratings|less than \\d{1,3}% positive ratings|\\d{1,3}% positive ratings|\\d{1,3}%\"\n",
    "    time_pattern = r\"ship on time\"\n",
    "    \n",
    "    # Find subjects\n",
    "    subjects = [keyword for keyword in subject_keywords if keyword in query.lower()]\n",
    "    subjects.extend([brand for brand in brand_names if brand in query.lower()])\n",
    "    \n",
    "    # Find limitations\n",
    "    limitations = re.findall(price_pattern, query)\n",
    "    limitations.extend(re.findall(rating_pattern, query))\n",
    "    if \"top-rated sellers\" in query.lower() or \"highly rated sellers\" in query.lower():\n",
    "        limitations.append(\"top-rated sellers\")\n",
    "    if re.search(time_pattern, query, re.IGNORECASE):\n",
    "        limitations.append(\"ship on time\")\n",
    "\n",
    "    # Check if there are specific seller names mentioned\n",
    "    for seller in seller_names:\n",
    "        if seller in query.lower():\n",
    "            limitations.append(f\"sold by {seller}\")\n",
    "\n",
    "    # return {\"subjects\": subjects, \"limitations\": limitations}\n",
    "    return limitations\n",
    "\n",
    "# Redefining example queries\n",
    "query = \"Show me watches from sellers with more than 90% positive ratings.\"\n",
    "extracted_info = extract_info_simple(query)\n",
    "extracted_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Products Based On Limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product 06',\n",
       " 'Product 08',\n",
       " 'Product 12',\n",
       " 'Product 13',\n",
       " 'Product 16',\n",
       " 'Product 18']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load the product data from a CSV file and preprocess it.\"\"\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['Discounted Price'] = data['Price Details'].apply(\n",
    "        lambda x: min(map(int, re.findall(r'Discounted: Rs\\. (\\d+)', x)))\n",
    "    )\n",
    "    data['Positive Seller Ratings'] = data['Positive Seller Ratings'].str.rstrip('%').astype(int)\n",
    "    data['Ship on Time'] = data['Ship on Time'].str.rstrip('%').astype(int)\n",
    "    return data\n",
    "\n",
    "def parse_limitation(limitation):\n",
    "    \"\"\"Parse the limitation string into a structured dictionary.\"\"\"\n",
    "    if 'between Rs.' in limitation:\n",
    "        low, high = map(int, re.findall(r'\\d+', limitation))\n",
    "        return {'price_range': (low, high)}\n",
    "    elif 'Rs.' in limitation:\n",
    "        price = int(re.findall(r'\\d+', limitation)[0])\n",
    "        return {'price_exact': price}\n",
    "    elif 'sold by' in limitation:\n",
    "        seller = limitation.split('sold by ')[1].strip()\n",
    "        return {'seller_name': seller}\n",
    "    elif 'top-rated sellers' in limitation:\n",
    "        return {'top_rated_sellers': 90}\n",
    "    elif '%' in limitation:\n",
    "        rating = int(re.findall(r'\\d+', limitation)[0])\n",
    "        return {'top_rated_sellers': rating}\n",
    "    elif 'ship on time' in limitation:\n",
    "        return {'ship_on_time': 100}\n",
    "    else:\n",
    "        return None  # Handle unrecognized input\n",
    "\n",
    "def filter_products(data, limitation_dict):\n",
    "    \"\"\"Apply filters to the data based on parsed limitations.\"\"\"\n",
    "    if limitation_dict is None:\n",
    "        return []\n",
    "    key, value = next(iter(limitation_dict.items()))\n",
    "    if key == 'price_exact':\n",
    "        filtered_data = data[data['Discounted Price'] == value]\n",
    "    elif key == 'price_range':\n",
    "        filtered_data = data[(data['Discounted Price'] >= value[0]) & (data['Discounted Price'] <= value[1])]\n",
    "    elif key == 'seller_name':\n",
    "        filtered_data = data[data['Seller Name'].str.contains(value, case=False, na=False)]\n",
    "    elif key == 'top_rated_sellers':\n",
    "        filtered_data = data[data['Positive Seller Ratings'] >= value]\n",
    "    elif key == 'ship_on_time':\n",
    "        filtered_data = data[data['Ship on Time'] == value]\n",
    "    return filtered_data['Product Number'].tolist()\n",
    "\n",
    "# Load data\n",
    "data = load_data('FinalProductsList.csv')\n",
    "\n",
    "# Example limitation\n",
    "limitation = \"'90%', 'more than 90% positive ratings'\"\n",
    "\n",
    "# Parse and filter products based on the limitation\n",
    "parsed_limitation = parse_limitation(limitation)\n",
    "matching_product_numbers = filter_products(data, parsed_limitation)\n",
    "\n",
    "matching_product_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortlisting Products From All Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_products(input_filename, output_filename, matching_product_numbers):\n",
    "    with open(input_filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Prepare to collect matching lines\n",
    "    matching_lines = []\n",
    "\n",
    "    # Filter lines based on matching_product_numbers\n",
    "    if matching_product_numbers:\n",
    "        # Create a set for faster lookup\n",
    "        product_set = set(matching_product_numbers)\n",
    "        for line in lines:\n",
    "            # Assuming each line starts with a product identifier like \"Product XX:\"\n",
    "            product_number = line.split(':', 1)[0].strip()\n",
    "            if product_number in product_set:\n",
    "                matching_lines.append(line)\n",
    "    else:\n",
    "        # If matching_product_numbers is empty, select all lines\n",
    "        matching_lines = lines\n",
    "\n",
    "    # Write the selected lines to the output file\n",
    "    with open(output_filename, 'w') as file:\n",
    "        file.writelines(matching_lines)\n",
    "\n",
    "filter_products('FinalProductsList.txt', 'ProductsList.txt', matching_product_numbers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
