{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8290950,"sourceType":"datasetVersion","datasetId":4925150}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1781563d3609428c91b951d81ed529c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f5dd68a97cc428fa056b0942d8e5cb5","IPY_MODEL_7054ecf136824d099c053436dfe4dce2","IPY_MODEL_8e9149923dde4cf9b61c4fa4c42265f1"],"layout":"IPY_MODEL_65a171d4f3874aeeb9bab2f225c4260f"}},"2f5dd68a97cc428fa056b0942d8e5cb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b4b2509f5bd49cabca939264ba9b95f","placeholder":"​","style":"IPY_MODEL_4dc6e5c0acfb4cd1a5495697c7f0388b","value":"Loading checkpoint shards: 100%"}},"7054ecf136824d099c053436dfe4dce2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be6cb5e81bb14fd6b94c451c39bf8878","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_417f5d8793d049e5831ecbe77e9fbe6d","value":2}},"8e9149923dde4cf9b61c4fa4c42265f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd5249016b29446b996fe65c215a707a","placeholder":"​","style":"IPY_MODEL_2411354bd0964d199bfc4d87772b95b4","value":" 2/2 [00:29&lt;00:00, 12.94s/it]"}},"65a171d4f3874aeeb9bab2f225c4260f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b4b2509f5bd49cabca939264ba9b95f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dc6e5c0acfb4cd1a5495697c7f0388b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be6cb5e81bb14fd6b94c451c39bf8878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"417f5d8793d049e5831ecbe77e9fbe6d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd5249016b29446b996fe65c215a707a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2411354bd0964d199bfc4d87772b95b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPpbCvsGGM_V","outputId":"c15a0093-f866-430f-8b42-d676ebf805bf","execution":{"iopub.status.busy":"2024-05-02T15:03:03.732380Z","iopub.execute_input":"2024-05-02T15:03:03.733412Z","iopub.status.idle":"2024-05-02T15:03:03.740916Z","shell.execute_reply.started":"2024-05-02T15:03:03.733363Z","shell.execute_reply":"2024-05-02T15:03:03.739708Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface_hub\nfrom huggingface_hub import login\nlogin(token=\"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\")","metadata":{"id":"Wli_olAvlUI-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"26eb8bac-4de2-4aac-ca9f-895398a2bb80","execution":{"iopub.status.busy":"2024-05-02T15:03:03.743136Z","iopub.execute_input":"2024-05-02T15:03:03.744183Z","iopub.status.idle":"2024-05-02T15:03:19.695086Z","shell.execute_reply.started":"2024-05-02T15:03:03.744144Z","shell.execute_reply":"2024-05-02T15:03:19.693507Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\nToken has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers.generation import GenerationConfig\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport textwrap\nimport torch\nimport time\n\n!pip install tiktoken\n!pip install tiktoken transformers_stream_generator einops optimum auto-gptq\n\nfrom transformers import pipeline\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\npipe = pipeline(\"text-generation\", model=\"microsoft/phi-2\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1781563d3609428c91b951d81ed529c5","2f5dd68a97cc428fa056b0942d8e5cb5","7054ecf136824d099c053436dfe4dce2","8e9149923dde4cf9b61c4fa4c42265f1","65a171d4f3874aeeb9bab2f225c4260f","2b4b2509f5bd49cabca939264ba9b95f","4dc6e5c0acfb4cd1a5495697c7f0388b","be6cb5e81bb14fd6b94c451c39bf8878","417f5d8793d049e5831ecbe77e9fbe6d","cd5249016b29446b996fe65c215a707a","2411354bd0964d199bfc4d87772b95b4"]},"id":"r8GJCNKHF_Hl","outputId":"672e93e9-d7c5-40a0-dfbe-339c97d0b055","execution":{"iopub.status.busy":"2024-05-02T15:03:19.696956Z","iopub.execute_input":"2024-05-02T15:03:19.697408Z","iopub.status.idle":"2024-05-02T15:06:07.216747Z","shell.execute_reply.started":"2024-05-02T15:03:19.697368Z","shell.execute_reply":"2024-05-02T15:06:07.215158Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.6.0\nRequirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.6.0)\nCollecting transformers_stream_generator\n  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting optimum\n  Downloading optimum-1.19.1-py3-none-any.whl.metadata (19 kB)\nCollecting auto-gptq\n  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: transformers>=4.26.1 in /opt/conda/lib/python3.10/site-packages (from transformers_stream_generator) (4.39.3)\nCollecting coloredlogs (from optimum)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.12)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.1.2+cpu)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (0.22.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (2.18.0)\nRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.29.3)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.2.0)\nCollecting rouge (from auto-gptq)\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nCollecting gekko (from auto-gptq)\n  Downloading gekko-1.1.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.4.3)\nCollecting peft>=0.5.0 (from auto-gptq)\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.2)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.15.2)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (3.20.3)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.9.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.4)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.19.1-py3-none-any.whl (417 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.0/417.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gekko-1.1.1-py3-none-any.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers_stream_generator\n  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12424 sha256=942ae64ca4b7c5c7d944aa73b87e5e2b743ea0a319a3d98ad91f34377f95926d\n  Stored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\nSuccessfully built transformers_stream_generator\nInstalling collected packages: rouge, humanfriendly, gekko, einops, coloredlogs, transformers_stream_generator, peft, optimum, auto-gptq\nSuccessfully installed auto-gptq-0.7.1 coloredlogs-15.0.1 einops-0.8.0 gekko-1.1.1 humanfriendly-10.0 optimum-1.19.1 peft-0.10.0 rouge-1.0.1 transformers_stream_generator-0.0.5\n","output_type":"stream"},{"name":"stderr","text":"2024-05-02 15:04:02.047024: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-02 15:04:02.047108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-02 15:04:02.049008: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8152891b2bd2441884369f0631695566"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e550ebf5aa18453ebb5ddb0a0a315d60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0567b3e6709847569902a073a5d1aaaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1edba2cc438341f9bdb8e82acf9a30bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1059b97a777842328ed7c31ad6eb09d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e40deb55e6a64738979029fc7405dc43"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"350e8000cd554dcfa9ae655107c52ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33a17a8452084f1eb04648305d84e21f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a2bd3861af42fd834dfd354479913f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1830626df5094f089156af70edcb2a83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fe141a56358421ba470bdcbd07c693e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b955750de2bd4d0591f982b8e52264cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd6427656bd54392b84d60d7cf0bd3aa"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_completion(prompt):\n    messages = [{\n        \"role\": \"user\",\n        \"content\": prompt }]\n    prompt2 = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    outputs = pipe(prompt2, max_new_tokens=150, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n    return outputs[0][\"generated_text\"]","metadata":{"id":"qffsI2cwF_Hn","execution":{"iopub.status.busy":"2024-05-02T15:06:07.218733Z","iopub.execute_input":"2024-05-02T15:06:07.219754Z","iopub.status.idle":"2024-05-02T15:06:07.228646Z","shell.execute_reply.started":"2024-05-02T15:06:07.219676Z","shell.execute_reply":"2024-05-02T15:06:07.227040Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Main Data","metadata":{"id":"yCrnSKuGF_Ho"}},{"cell_type":"code","source":"# Define the question\nquestion = \"What are your refund policies?\"\n\n# Read the content from the output file\nwith open('/kaggle/input/ita-proj/outputMain.txt', 'r') as file:\n    content = file.read().strip()\n\n# Construct the prompt to pass to the LLM\nprompt = f\"\"\"\nBased on the detailed information below, please provide a comprehensive answer to the customer's query:\n\n{content}\n\nQuestion: {question}\n\nYour response should comprehensively integrate the information provided, accurately reflecting the key points and offering a clear, well-structured answer.\n\"\"\"\n\n# Generate the response using the LLM\nstart_time = time.time()\nresponse = get_completion(prompt)\nend_time = time.time()\nprint(response)\nprint(\"Time taken: \", end_time - start_time)","metadata":{"id":"uC-K6QNHF_Hp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6d9c6ac-139f-4213-a2c0-6aa3719068df","execution":{"iopub.status.busy":"2024-05-02T15:06:07.232146Z","iopub.execute_input":"2024-05-02T15:06:07.232671Z","iopub.status.idle":"2024-05-02T15:07:59.823493Z","shell.execute_reply.started":"2024-05-02T15:06:07.232620Z","shell.execute_reply":"2024-05-02T15:07:59.822011Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\nNo chat template is defined for this tokenizer - using a default chat template that implements the ChatML format (without BOS/EOS tokens!). If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<|im_start|>user\n\nBased on the detailed information below, please provide a comprehensive answer to the customer's query:\n\nIf the item received is damaged, defective, incorrect, or incomplete, a refund will be issued based on Daraz's assessment. Note: For device-related issues after usage or expiration of return policy period, please check if the item is covered under Seller or Brand Warranty. Items that are non-returnable: Any custom-made items\" What is the cancellation and return policy for Buy More, Save More orders? Partial cancellations are not allowed but partial returns are allowed on Buy More, Save More orders i. e. you will not be able to cancel 1 or 2 products in your order and would instead have to cancel the entire order. But if you decide to apply for a return, you can return certain items out of your total Buy More, Save More order. If a certain number of products from a Buy More, Save More order are eligible for a return, partial refund will be issued to the customer after these items have been returned by the customer & quality checked by Daraz. Partial refunds are calculated on item level of each bundle. In case you have received your order but are not satisfied with your purchase, you can submit a return request within 14 days from the day it is delivered to you. Decision on returns and refunds taken by Daraz will be final in its sole discretion. In case a customer tries to circumvent the terms and conditions and abuse subsidies by creating new accounts, they will be unable to place their order. \"\n\nQuestion: What are your refund policies?\n\nYour response should comprehensively integrate the information provided, accurately reflecting the key points and offering a clear, well-structured answer.\n<|im_end|>\n<|im_start|>assistant\n\nDear customer,\n\nThank you for reaching out. I would be happy to assist you with your query regarding our refund policies.\n\nAs stated, if the item you have received is damaged, defective, incorrect, or incomplete, Daraz will assess the situation and provide a refund accordingly. It is important to note that for device-related issues after usage or expiration of the return policy period, please check if the item is covered under Seller or Brand Warranty.\n\nIn the case of Buy More, Save More orders, partial cancellations are not allowed. However, partial returns are permitted. If you decide to return certain items from your order, you will be able to do so. However, if a certain number of products from your\nTime taken:  112.56360626220703\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Seller Data","metadata":{"id":"_6Iyej9lF_Hp"}},{"cell_type":"code","source":"# Define the question\nquestion = \"Can I make product bundles on Daraz?\"\n\n# Read the content from the output file\nwith open('/kaggle/input/ita-proj/outputSeller.txt', 'r') as file:\n    content = file.read().strip()\n\n# Construct the prompt to pass to the LLM\nprompt = f\"\"\"\nBased on the detailed information below, please provide a comprehensive answer to the customer's query:\n\n{content}\n\nQuestion: {question}\n\nYour response should comprehensively integrate the information provided, accurately reflecting the key points and offering a clear, well-structured answer.\n\"\"\"\n\n# Generate the response using the LLM\nstart_time = time.time()\nresponse = get_completion(prompt)\nend_time = time.time()\nprint(response)\nprint(\"Time taken: \", end_time - start_time)","metadata":{"id":"k83SlCnlF_Hp","execution":{"iopub.status.busy":"2024-05-02T15:07:59.825019Z","iopub.execute_input":"2024-05-02T15:07:59.825889Z","iopub.status.idle":"2024-05-02T15:09:13.254336Z","shell.execute_reply.started":"2024-05-02T15:07:59.825840Z","shell.execute_reply":"2024-05-02T15:09:13.252782Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<|im_start|>user\n\nBased on the detailed information below, please provide a comprehensive answer to the customer's query:\n\nYou must deactivate one bundle feature for that SKU in order to reactivate another. Bundles: Buy 1 Get 1 Free A common form of sales promotion also known as two for one whilst the cost per item is proportionately cheaper than if bought on its own, it is not actually half price. Bundles: Combo A promotion where different products are sold together as a set with one or more items at discounted prices Products with high views and sales mix with less popular products. Minimum 5 customs products should be there if a seller is selling only custom made products What are the Benefits of Product Customization? Match Customer Demand Increase sales and competitive edge Customer engagement Build brand loyalty Gain market research\" Why should I create bundles? Sellers can create bundles to differentiate their deals from competitors, especially in high-priced competitive categories It's a great opportunity to sell low-cost items as part of a bundle Bundles allow sellers to clear their inventory of whatever products they choose Additionally, bundles are a foolproof way to attract customers and increase conversion rate, sales and enhance overall performance. Sellers sell a package or set of goods for a lower price than they would charge if the customer bought all of them seperately. Minimum 5 customs products should be there if a seller is selling only custom made products What are the Benefits of Product Customization? Match Customer Demand Increase sales and competitive edge Customer engagement Build brand loyalty Gain market research\" What are the types of Product Bundling? Minimum 5 customs products should be there if a seller is selling only custom made products What are the Benefits of Product Customization?\n\nQuestion: Can I make product bundles on Daraz?\n\nYour response should comprehensively integrate the information provided, accurately reflecting the key points and offering a clear, well-structured answer.\n<|im_end|>\n<|im_start|>assistant\n\nYes, you can make product bundles on Daraz. This allows you to offer customers a variety of options and price points for your products, which can help increase sales and customer engagement. Additionally, bundling can help you clear out inventory and attract new customers. However, it's important to carefully consider which products to bundle together and what the optimal price points will be to maximize sales and profits.\n<|im_end|>\n\nTime taken:  73.4133243560791\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Product Data","metadata":{"id":"RI7g1_VXF_Hq"}},{"cell_type":"code","source":"# Define the question\nquestion = \"Can you list watches between Rs. 1000 and Rs. 2000?\"\n\n# Read the content from the output file\nwith open('/kaggle/input/ita-proj/outputProducts.txt', 'r') as file:\n    content = file.read().strip()\n\n# Construct the prompt to pass to the LLM\nprompt = f\"\"\"\nCustomer Question: {question}\nProduct List:\n\n{content}\n\nBased on the above product list, please provide a helpful and engaging answer that encourages the customer to consider the options and possibly make a purchase. Highlight the key features and benefits of the products listed.\n\"\"\"\n\n# Generate the response using the LLM\nstart_time = time.time()\nresponse = get_completion(prompt)\nend_time = time.time()\nprint(response)\nprint(\"Time taken: \", end_time - start_time)","metadata":{"id":"JJRKrlVfF_Hq","execution":{"iopub.status.busy":"2024-05-02T15:09:13.256246Z","iopub.execute_input":"2024-05-02T15:09:13.256770Z","iopub.status.idle":"2024-05-02T15:11:16.808004Z","shell.execute_reply.started":"2024-05-02T15:09:13.256721Z","shell.execute_reply":"2024-05-02T15:11:16.806586Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<|im_start|>user\n\nCustomer Question: Can you list watches between Rs. 1000 and Rs. 2000?\nProduct List:\n\nProduct 04: Product Name = Men Quartz Watch for Waterproof Vacuum Plating Strap with Car Wheel Rim Hub Design Sport Automatic Wristwatch (Does not rotate), Product Category = Watches Sunglasses Jewellery/Watches/Men/Fashion, Brand Name = No Brand, Seller Name = D&K Online, URL = https://www.daraz.pk/products/-i411043073-s1964553711.html?search=1, Price Details = Original: Rs. 3999, Discounted: Rs. 1768 | Original: Rs. 3999, Discounted: Rs. 1869 | Original: Rs. 3999, Discounted: Rs. 1769 | Original: Rs. 3999, Discounted: Rs. 1768 | Original: Rs. 3999, Discounted: Rs. 1868, Positive Seller Ratings = 82%, Ship on Time = 100%, Return Policy = 14 days free & easy return (Change of mind is not applicable)\nProduct 10: Product Name = 2022 trend full-automatic quartz movement men's watch wheel non mechanical watch wrist watch fashion men's watch, Product Category = Watches Sunglasses Jewellery/Watches/Men/Fashion, Brand Name = No Brand, Seller Name = lamgool Electronic, URL = https://www.daraz.pk/products/2022-i366103747-s1819200832.html?search=1, Price Details = Original: Rs. 1836, Discounted: Rs. 1410, Positive Seller Ratings = 81%, Ship on Time = 100%, Return Policy = 14 days free & easy return (Change of mind is not applicable)\nProduct 17: Product Name = Qiunery YESURPRISE Unisex Antique Case Vintage Brass Rib Chain Quartz Pocket Watch Train, Product Category = Watches Sunglasses Jewellery/Watches/Men/Fashion, Brand Name = No Brand, Seller Name = Qiunery, URL = https://www.daraz.pk/products/qiunery-yesur-i202992571-s1402460810.html?search=1, Price Details = Original: Rs. 1790, Discounted: Rs. 1250, Positive Seller Ratings = 82%, Ship on Time = 100%, Return Policy = 14 days free & easy return (Change of mind is not applicable)\n\nBased on the above product list, please provide a helpful and engaging answer that encourages the customer to consider the options and possibly make a purchase. Highlight the key features and benefits of the products listed.\n<|im_end|>\n<|im_start|>assistant\n\nDear [Customer Name],\n\nThank you for your inquiry about watches in the range of Rs. 1000 to Rs. 2000. We understand that you are looking for affordable yet stylish options, and we have a few products that may be of interest to you.\n\nOur first product, the Men Quartz Watch for Waterproof Vacuum Plating Strap with Car Wheel Rim Hub Design Sport Automatic Wristwatch, is a great choice for those who want a durable and stylish watch that can withstand water and other elements. It is also water-resistant up to 100 meters, making it perfect for outdoor activities.\n\nAnother option is the 2022 trend full-automatic quartz movement men's watch wheel non mechanical watch wrist watch fashion men's watch.\nTime taken:  123.5328278541565\n","output_type":"stream"}]}]}